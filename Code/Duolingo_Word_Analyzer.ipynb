{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2fddca9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['札幌' '大晦日' '福袋' ... 'すし' 'ください' 'おちゃ']\n",
      "Duolingo_Unique words saved to Duolingo_unique_words.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import MeCab\n",
    "\n",
    "# Load the list of words\n",
    "duo = np.loadtxt(\"SRC/Duolingo_JP_Wordlist_2024-12-09.txt\", encoding=\"utf-8\", dtype=\"str\")\n",
    "print(duo)\n",
    "\n",
    "# Initialize MeCab Tagger for word segmentation\n",
    "wakati = MeCab.Tagger(\"-Owakati\")\n",
    "\n",
    "# Parse each word individually and collect the results\n",
    "parsed_words = []\n",
    "for word in duo:\n",
    "    # Parse the word and split it into tokens\n",
    "    parsed = wakati.parse(word).split()\n",
    "    parsed_words.extend(parsed)\n",
    "\n",
    "# Convert the list of parsed words to a Pandas DataFrame\n",
    "df = pd.DataFrame(parsed_words, columns=[\"Word\"])\n",
    "\n",
    "# Remove duplicates, keeping only the first occurrence\n",
    "df_unique = df.drop_duplicates(subset=[\"Word\"], keep='first').reset_index(drop=True)\n",
    "\n",
    "# Define the output file name\n",
    "output_file = \"Duolingo_unique_words.csv\"\n",
    "df_unique.to_csv(output_file, index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"Duolingo_Unique words saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "dfe75636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Word  Line_Number  Count\n",
      "0     の            1  19286\n",
      "1     に            2  16022\n",
      "2     て            3  14089\n",
      "3     を            4  12896\n",
      "4     は            5  12197\n",
      "5     た            6  11829\n",
      "6     が            7  10464\n",
      "7     と            8   9878\n",
      "8     で            9   8338\n",
      "9     し           10   5963\n",
      "10    も           11   5349\n",
      "11    な           12   4287\n",
      "12    だ           13   4017\n",
      "13   ない           14   3743\n",
      "14    か           15   3401\n",
      "15   から           17   2642\n",
      "16    い           19   2237\n",
      "17    ん           20   2155\n",
      "18   よう           22   2013\n",
      "19   それ           26   1493\n",
      "20    さ           27   1485\n",
      "21   その           29   1429\n",
      "22    よ           31   1277\n",
      "23    的           32   1176\n",
      "24   ます           33   1141\n",
      "25   もの           36   1093\n",
      "26    や           37   1059\n",
      "27    何           38   1001\n",
      "28    人           39    970\n",
      "29   この           40    954\n",
      "30   たち           41    937\n",
      "31    ね           42    926\n",
      "32    お           43    898\n",
      "33    ば           44    879\n",
      "34    僕           47    794\n",
      "35   いい           49    772\n",
      "36    私           50    763\n",
      "37   さん           51    731\n",
      "38   これ           52    707\n",
      "39    一           53    706\n",
      "40    中           54    689\n",
      "41    き           55    681\n",
      "42   どう           58    622\n",
      "43  そして           63    573\n",
      "44   考え           64    572\n",
      "45    つ           65    570\n",
      "46    年           70    530\n",
      "47    あ           71    519\n",
      "48    彼           72    516\n",
      "49    目           78    488\n"
     ]
    }
   ],
   "source": [
    "pfreq = pd.read_csv('Personalized_Frequency_List.csv', encoding=\"utf-8-sig\")\n",
    "duolist = pd.read_csv('Duolingo_unique_words.csv', encoding=\"utf-8\", header=None, names=[\"Word\"])\n",
    "\n",
    "# Create an empty list to hold the result (word and line number)\n",
    "duolingo_frequency = []\n",
    "\n",
    "# Compare each word in the Duolingo list with the Personalized list\n",
    "for duolingo_word in duolist[\"Word\"]:\n",
    "    # Try to find the word in the personalized list\n",
    "    match = pfreq[pfreq[\"Word\"] == duolingo_word]\n",
    "    if not match.empty:\n",
    "        # Get the line number (index + 1 for human-readable index)\n",
    "        line_number = match.index[0] + 1  # Adding 1 to make the line number 1-based\n",
    "        count = match[\"Total Count\"].values[0]  # Get the count of the word from the Personalized list (not 'Total Count')\n",
    "        duolingo_frequency.append([duolingo_word, line_number, count])\n",
    "    else:\n",
    "        # If no match, assign None or some other placeholder\n",
    "        duolingo_frequency.append([duolingo_word, None, None])\n",
    "\n",
    "# Create a new DataFrame from the list\n",
    "duolingo_frequency_df = pd.DataFrame(duolingo_frequency, columns=[\"Word\", \"Line_Number\", \"Count\"])\n",
    "\n",
    "# Convert \"Line\" and \"Count\" columns to integers (where applicable)\n",
    "duolingo_frequency_df[\"Line_Number\"] = duolingo_frequency_df[\"Line_Number\"].astype('Int64')  # 'Int64' allows None values\n",
    "duolingo_frequency_df[\"Count\"] = duolingo_frequency_df[\"Count\"].astype('Int64')  # Convert to integer\n",
    "\n",
    "df_sorted = duolingo_frequency_df.sort_values(\n",
    "    by=[\"Line_Number\"], \n",
    "    ascending=[True],  # Ascending for \"Line_Number\" and descending for \"Count\"\n",
    "    na_position=\"last\"  # Place None/NA values at the end\n",
    ").reset_index(drop=True)\n",
    "\n",
    "df_sorted.to_csv(\"DuolingoFrequency.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "print(df_sorted.head(50))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
